{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install openpyxl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:45:46.733789Z","iopub.execute_input":"2024-11-14T20:45:46.734560Z","iopub.status.idle":"2024-11-14T20:45:59.822031Z","shell.execute_reply.started":"2024-11-14T20:45:46.734511Z","shell.execute_reply":"2024-11-14T20:45:59.820934Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load the Excel file\nexcel_file = pd.ExcelFile('/kaggle/input/t-hsab/T-HSAB.xlsx')\n\n# Print all sheet names in the Excel file\nprint(excel_file.sheet_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:47:53.001379Z","iopub.execute_input":"2024-11-14T20:47:53.002292Z","iopub.status.idle":"2024-11-14T20:47:53.328052Z","shell.execute_reply.started":"2024-11-14T20:47:53.002237Z","shell.execute_reply":"2024-11-14T20:47:53.327161Z"}},"outputs":[{"name":"stdout","text":"['T-HSAB_Annotated']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define your column names, e.g., 'text' and 'label'\ncolumn_names = ['text', 'label']\n\n# Load the data with specified column names\ndf = pd.read_excel('/kaggle/input/t-hsab/T-HSAB.xlsx', sheet_name='T-HSAB_Annotated', header=None, names=column_names)\n\n# Display the first few rows\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:24:48.364718Z","iopub.execute_input":"2024-11-14T21:24:48.365133Z","iopub.status.idle":"2024-11-14T21:24:49.008095Z","shell.execute_reply.started":"2024-11-14T21:24:48.365093Z","shell.execute_reply":"2024-11-14T21:24:49.007088Z"}},"outputs":[{"name":"stdout","text":"                                                text   label\n0  اسغي ياشعب تونس تدعوا بالاسلام كفار الحمدلله ن...    hate\n1  قطع يد السارق توفرت الشروط شرط الحد الأدنى قيم...  normal\n2                             تلوموش لطفي لعبدلي شرف  normal\n3  مستغرب شعب يسمع تفاهة شانو لى الدرجة الشعب تاف...  normal\n4  هههخ غزلتني مافهمتش شمدخلها الموضوع تتنطر وحده...  normal\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Check for missing values\nprint(\"Missing values per column:\\n\", df.isnull().sum())\n\n# Drop any rows with missing values\ndf = df.dropna()\n\n# Confirm the class distribution\nprint(\"\\nClass distribution:\\n\", df['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:25:41.423944Z","iopub.execute_input":"2024-11-14T21:25:41.424816Z","iopub.status.idle":"2024-11-14T21:25:41.441224Z","shell.execute_reply.started":"2024-11-14T21:25:41.424767Z","shell.execute_reply":"2024-11-14T21:25:41.439993Z"}},"outputs":[{"name":"stdout","text":"Missing values per column:\n text     0\nlabel    0\ndtype: int64\n\nClass distribution:\n label\nnormal     3820\nabusive    1126\nhate       1078\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from sklearn.utils import resample\n\n# Separate majority and minority classes\ndf_majority = df[df['label'] == 'normal']\ndf_abusive = df[df['label'] == 'abusive']\ndf_hate = df[df['label'] == 'hate']\n\n# Upsample minority classes\ndf_abusive_upsampled = resample(df_abusive, replace=True, n_samples=len(df_majority), random_state=42)\ndf_hate_upsampled = resample(df_hate, replace=True, n_samples=len(df_majority), random_state=42)\n\n# Combine majority class with upsampled minority classes\ndf_balanced = pd.concat([df_majority, df_abusive_upsampled, df_hate_upsampled])\n\n# Shuffle the balanced dataset\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Check new distribution\nprint(df_balanced['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:25:48.108224Z","iopub.execute_input":"2024-11-14T21:25:48.108935Z","iopub.status.idle":"2024-11-14T21:25:48.131598Z","shell.execute_reply.started":"2024-11-14T21:25:48.108892Z","shell.execute_reply":"2024-11-14T21:25:48.130614Z"}},"outputs":[{"name":"stdout","text":"label\nabusive    3820\nhate       3820\nnormal     3820\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:27:22.616075Z","iopub.execute_input":"2024-11-14T21:27:22.616891Z","iopub.status.idle":"2024-11-14T21:27:22.625800Z","shell.execute_reply.started":"2024-11-14T21:27:22.616847Z","shell.execute_reply":"2024-11-14T21:27:22.624458Z"}},"outputs":[{"name":"stdout","text":"                                                text    label  encoded_label\n0                                     شرف متعكم لقحب  abusive              2\n1  راجل وسيدهم وديع المستويات الكلاب والطحانه يمش...  abusive              2\n2  الشاب بشير كرهتوا الحلقة ظهر فارغ ثقافيا فكريا...  abusive              2\n3  اخوكم الجزاءر شعب ركيك وبدون معنى الاسلام دين ...     hate              1\n4  حرية مؤخرتي يتشاف يفطر قدام العباد ندخلوا بالك...  abusive              2\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Custom label mapping\nlabel_map = {'normal': 0, 'hate': 1, 'abusive': 2}\n\n# Apply the custom label mapping to the DataFrame\ndf_balanced['encoded_label'] = df_balanced['label'].map(label_map)\n\n# Check the label encoding\nprint(\"Custom Label Encoding:\", df_balanced[['label', 'encoded_label']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:27:06.382239Z","iopub.execute_input":"2024-11-14T21:27:06.383325Z","iopub.status.idle":"2024-11-14T21:27:06.402328Z","shell.execute_reply.started":"2024-11-14T21:27:06.383263Z","shell.execute_reply":"2024-11-14T21:27:06.401234Z"}},"outputs":[{"name":"stdout","text":"Custom Label Encoding:          label  encoded_label\n0      abusive              2\n1      abusive              2\n2      abusive              2\n3         hate              1\n4      abusive              2\n...        ...            ...\n11455     hate              1\n11456  abusive              2\n11457  abusive              2\n11458   normal              0\n11459  abusive              2\n\n[11460 rows x 2 columns]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(df_balanced.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n\n# Initialize tokenizer for TuniBert model\ntokenizer = AutoTokenizer.from_pretrained(\"AhmedBou/TuniBert\")\n\n# Define a Dataset class for tokenizing and converting text to tensors\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',  # Padding to max_length\n            max_length=self.max_length,  # Define max sequence length\n            return_tensors=\"pt\"  # Return PyTorch tensors\n        )\n        # Flatten the tensors and add the label\n        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Remove batch dimension\n        item['labels'] = torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n        return item\n\n\n\n\n\n# Split data into training and validation sets (80-20 split)\ntexts = df_balanced['text'].tolist()\nlabels = df_balanced['encoded_label'].tolist()  # Use the encoded labels\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n\n# Create Dataset instances for training and validation\ntrain_dataset = TextDataset(train_texts, train_labels, tokenizer)\nval_dataset = TextDataset(val_texts, val_labels, tokenizer)\n\n# Create DataLoader instances to load data in batches for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\n# You can now use `train_loader` and `val_loader` with a Hugging Face Trainer or manual training loop.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:27:56.556748Z","iopub.execute_input":"2024-11-14T21:27:56.557131Z","iopub.status.idle":"2024-11-14T21:27:56.781134Z","shell.execute_reply.started":"2024-11-14T21:27:56.557091Z","shell.execute_reply":"2024-11-14T21:27:56.780106Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"print(\"Custom Label Mapping:\", label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:28:42.830651Z","iopub.execute_input":"2024-11-14T21:28:42.831796Z","iopub.status.idle":"2024-11-14T21:28:42.839169Z","shell.execute_reply.started":"2024-11-14T21:28:42.831733Z","shell.execute_reply":"2024-11-14T21:28:42.838285Z"}},"outputs":[{"name":"stdout","text":"Custom Label Mapping: {'normal': 0, 'hate': 1, 'abusive': 2}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"AhmedBou/TuniBert\", num_labels=len(set(labels)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:28:51.250013Z","iopub.execute_input":"2024-11-14T21:28:51.250393Z","iopub.status.idle":"2024-11-14T21:28:51.525864Z","shell.execute_reply.started":"2024-11-14T21:28:51.250357Z","shell.execute_reply":"2024-11-14T21:28:51.524860Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=20,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=10,\n    eval_strategy=\"epoch\",  # Use eval_strategy instead of evaluation_strategy\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:46:33.125386Z","iopub.execute_input":"2024-11-14T21:46:33.126225Z","iopub.status.idle":"2024-11-14T21:46:33.174820Z","shell.execute_reply.started":"2024-11-14T21:46:33.126184Z","shell.execute_reply":"2024-11-14T21:46:33.173828Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:46:35.645246Z","iopub.execute_input":"2024-11-14T21:46:35.645669Z","iopub.status.idle":"2024-11-14T22:32:46.289476Z","shell.execute_reply.started":"2024-11-14T21:46:35.645632Z","shell.execute_reply":"2024-11-14T22:32:46.288705Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5740' max='5740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5740/5740 46:09, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.033500</td>\n      <td>0.502788</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.064800</td>\n      <td>0.502935</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.113600</td>\n      <td>0.522923</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.022400</td>\n      <td>0.452368</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.035900</td>\n      <td>0.519052</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.029500</td>\n      <td>0.568775</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.006800</td>\n      <td>0.429740</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.003300</td>\n      <td>0.659480</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.064400</td>\n      <td>0.454966</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.005600</td>\n      <td>0.567050</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000100</td>\n      <td>0.513789</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000100</td>\n      <td>0.516772</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000200</td>\n      <td>0.559099</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000800</td>\n      <td>0.650777</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000100</td>\n      <td>0.505973</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.000100</td>\n      <td>0.572432</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.000100</td>\n      <td>0.541894</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.004400</td>\n      <td>0.648380</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.000000</td>\n      <td>0.618362</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.008700</td>\n      <td>0.620779</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5740, training_loss=0.016004357453088237, metrics={'train_runtime': 2770.0887, 'train_samples_per_second': 66.193, 'train_steps_per_second': 2.072, 'total_flos': 1.206111906865152e+16, 'train_loss': 0.016004357453088237, 'epoch': 20.0})"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(eval_results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:35:46.923013Z","iopub.execute_input":"2024-11-14T22:35:46.923465Z","iopub.status.idle":"2024-11-14T22:35:57.710527Z","shell.execute_reply.started":"2024-11-14T22:35:46.923422Z","shell.execute_reply":"2024-11-14T22:35:57.709562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [72/72 00:10]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.6207791566848755, 'eval_runtime': 10.7781, 'eval_samples_per_second': 212.653, 'eval_steps_per_second': 6.68, 'epoch': 20.0}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"model.save_pretrained('./fine_tuned_tunibert')\ntokenizer.save_pretrained('./fine_tuned_tunibert')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:36:01.747473Z","iopub.execute_input":"2024-11-14T22:36:01.748364Z","iopub.status.idle":"2024-11-14T22:36:02.855446Z","shell.execute_reply.started":"2024-11-14T22:36:01.748322Z","shell.execute_reply":"2024-11-14T22:36:02.854515Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_tunibert/tokenizer_config.json',\n './fine_tuned_tunibert/special_tokens_map.json',\n './fine_tuned_tunibert/vocab.txt',\n './fine_tuned_tunibert/added_tokens.json',\n './fine_tuned_tunibert/tokenizer.json')"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"from transformers import pipeline\nimport random\n\n# Load the fine-tuned model and tokenizer\nfine_tuned_pipe = pipeline(\"text-classification\", model=\"./fine_tuned_tunibert\", tokenizer=tokenizer , device=0)\n\n# Define your label mapping for interpreting the results\nlabel_map = {0: 'normal', 1: 'hate', 2: 'abusive'}\n\n# Pick a random test sample (you can adjust it to use your own test data)\nrandom_idx = random.randint(0, len(val_texts) - 1)\nrandom_sample = val_texts[random_idx]\nreal_label = val_labels[random_idx]  # The real label corresponding to the sample\n\n# Get the prediction from the fine-tuned model\nresults = fine_tuned_pipe(random_sample)\n\n# Convert the model's label index to the real label\npredicted_label = results[0]['label']\npredicted_label_index = label_map[int(predicted_label.split('_')[1])]  # Extract label from 'LABEL_X' and map it\n\n# Print the prediction result\nprint(f\"Test Sentence: {random_sample}\")\nprint(f\"Real Label: {label_map[real_label]}\")\nprint(f\"Predicted Label: {predicted_label_index}, with confidence score: {results[0]['score']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:54:24.575661Z","iopub.execute_input":"2024-11-14T22:54:24.576057Z","iopub.status.idle":"2024-11-14T22:54:24.815116Z","shell.execute_reply.started":"2024-11-14T22:54:24.576018Z","shell.execute_reply":"2024-11-14T22:54:24.814073Z"}},"outputs":[{"name":"stdout","text":"Test Sentence: كلاب ضالة\nReal Label: abusive\nPredicted Label: abusive, with confidence score: 0.9999406337738037\n","output_type":"stream"}],"execution_count":165},{"cell_type":"code","source":"from transformers import pipeline\nfrom sklearn.metrics import accuracy_score\n\n# Load the fine-tuned model and tokenizer\nfine_tuned_pipe = pipeline(\"text-classification\", model=\"./fine_tuned_tunibert\", tokenizer=tokenizer, device=0)  # Use GPU if available\n\n# Define label mapping for interpretation (if necessary)\nlabel_map = {0: 'normal', 1: 'hate', 2: 'abusive'}\n\n# Create a function to evaluate accuracy on a test dataset\ndef evaluate_accuracy(test_texts, true_labels):\n    predicted_labels = []\n    \n    # Iterate through the test texts and get predictions\n    for text in test_texts:\n        # Get prediction from the model\n        result = fine_tuned_pipe(text)\n        \n        # Extract predicted label from the model output\n        # The 'label' is in the format 'LABEL_X', so we extract the index by splitting\n        predicted_label = result[0]['label']\n        \n        # Map the label from the model's output (e.g., 'LABEL_0', 'LABEL_1', 'LABEL_2') to the numeric index\n        predicted_label_index = int(predicted_label.split('_')[1])  # Extract the number after 'LABEL_'\n        \n        # Append the predicted label index\n        predicted_labels.append(predicted_label_index)\n    \n    # Calculate accuracy by comparing predicted labels to true labels\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    return accuracy\n\n# Example usage: Evaluate accuracy on validation set or test set\naccuracy = evaluate_accuracy(val_texts, val_labels)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:51:05.318160Z","iopub.execute_input":"2024-11-14T22:51:05.319098Z","iopub.status.idle":"2024-11-14T22:51:27.810100Z","shell.execute_reply.started":"2024-11-14T22:51:05.319054Z","shell.execute_reply":"2024-11-14T22:51:27.809153Z"}},"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 93.32%\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"import shutil\nimport os\n\ndef zip_folders(folder1, folder2, zip_name):\n    # Create a temporary directory to store both folders\n    temp_dir = 'temp_folder_for_zip'\n    os.makedirs(temp_dir, exist_ok=True)\n\n    # Copy both folders into the temporary directory\n    shutil.copytree(folder1, os.path.join(temp_dir, os.path.basename(folder1)))\n    shutil.copytree(folder2, os.path.join(temp_dir, os.path.basename(folder2)))\n\n    # Create a zip file containing both folders\n    shutil.make_archive(zip_name, 'zip', temp_dir)\n\n    # Remove the temporary directory after zipping\n    shutil.rmtree(temp_dir)\n    \n    print(f\"Zip file '{zip_name}.zip' created successfully!\")\n\n# Example usage\nzip_folders('/kaggle/working/fine_tuned_tunibert', '/kaggle/working/results/checkpoint-5740', '/kaggle/working/fine_tuned_tunibert')  # Replace 'folder1', 'folder2' with your folder paths\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T23:06:09.867290Z","iopub.execute_input":"2024-11-14T23:06:09.867703Z","iopub.status.idle":"2024-11-14T23:07:42.814244Z","shell.execute_reply.started":"2024-11-14T23:06:09.867666Z","shell.execute_reply":"2024-11-14T23:07:42.812744Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1788\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m-> 1788\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:198\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1143\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nbytes\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[170], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZip file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m created successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mzip_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/fine_tuned_tunibert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/results/checkpoint-5740\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/fine_tuned_tunibert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace 'folder1', 'folder2' with your folder paths\u001b[39;00m\n","Cell \u001b[0;32mIn[170], line 14\u001b[0m, in \u001b[0;36mzip_folders\u001b[0;34m(folder1, folder2, zip_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopytree(folder2, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(temp_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(folder2)))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create a zip file containing both folders\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Remove the temporary directory after zipping\u001b[39;00m\n\u001b[1;32m     17\u001b[0m shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1124\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             os\u001b[38;5;241m.\u001b[39mchdir(root_dir)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_cwd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:1009\u001b[0m, in \u001b[0;36m_make_zipfile\u001b[0;34m(base_name, base_dir, verbose, dry_run, logger, owner, group, root_dir)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[1;32m   1008\u001b[0m     arcname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(arcdirpath, name)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43mzf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marcname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madding \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1787\u001b[0m, in \u001b[0;36mZipFile.write\u001b[0;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1787\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m   1788\u001b[0m         shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(src, dest, \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/zipfile.py:1155\u001b[0m, in \u001b[0;36m_ZipWriteFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[0;32m-> 1155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zinfo\u001b[38;5;241m.\u001b[39mcompress_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"}],"execution_count":170},{"cell_type":"code","source":"from transformers import pipeline\nfrom sklearn.metrics import accuracy_score\n\n# Load the fine-tuned model and tokenizer from the checkpoint directory\ncheckpoint_path = \"/kaggle/working/results/checkpoint-5000\"  # Replace with the correct path to your checkpoint\nfine_tuned_pipe = pipeline(\"text-classification\", model=checkpoint_path, tokenizer=tokenizer, device=0)  # Use GPU if available\n\n# Define label mapping for interpretation (if necessary)\nlabel_map = {0: 'normal', 1: 'hate', 2: 'abusive'}\n\n# Create a function to evaluate accuracy on a test dataset\ndef evaluate_accuracy(test_texts, true_labels):\n    predicted_labels = []\n    \n    # Iterate through the test texts and get predictions\n    for text in test_texts:\n        # Get prediction from the model\n        result = fine_tuned_pipe(text)\n        \n        # Extract predicted label from the model output\n        predicted_label = result[0]['label']\n        \n        # Map the label from the model's output (e.g., 'LABEL_0', 'LABEL_1', 'LABEL_2') to the numeric index\n        predicted_label_index = int(predicted_label.split('_')[1])  # Extract the number after 'LABEL_'\n        \n        # Append the predicted label index\n        predicted_labels.append(predicted_label_index)\n    \n    # Calculate accuracy by comparing predicted labels to true labels\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    return accuracy\n\n# Example usage: Evaluate accuracy on validation set or test set\naccuracy = evaluate_accuracy(val_texts, val_labels)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T23:04:29.680710Z","iopub.execute_input":"2024-11-14T23:04:29.681081Z","iopub.status.idle":"2024-11-14T23:04:52.266530Z","shell.execute_reply.started":"2024-11-14T23:04:29.681048Z","shell.execute_reply":"2024-11-14T23:04:52.265498Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 93.94%\n","output_type":"stream"}],"execution_count":168},{"cell_type":"code","source":"import shutil\n\n# Specify the directory path you want to zip\nfolder_path = '/kaggle/working/results/checkpoint-5740'  # Replace with your folder path\noutput_zip_path = '/kaggle/working/results/checkpoint-5740'  # Replace with your desired output zip file path\n\n# Zip the folder\nshutil.make_archive(output_zip_path.replace('.zip', ''), 'zip', folder_path)\n\nprint(f\"Folder {folder_path} has been zipped to {output_zip_path}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T23:10:10.790407Z","iopub.execute_input":"2024-11-14T23:10:10.790792Z","iopub.status.idle":"2024-11-14T23:11:17.915027Z","shell.execute_reply.started":"2024-11-14T23:10:10.790755Z","shell.execute_reply":"2024-11-14T23:11:17.914075Z"}},"outputs":[{"name":"stdout","text":"Folder /kaggle/working/results/checkpoint-5740 has been zipped to /kaggle/working/results/checkpoint-5740.\n","output_type":"stream"}],"execution_count":177}]}